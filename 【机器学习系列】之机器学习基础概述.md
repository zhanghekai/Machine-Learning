作者：張張張張
github地址：https://github.com/zhanghekai
【转载请注明出处，谢谢！】

## 一、机器学习概述

`机器学习(Machine Learning,ML)` 是使用计算机来彰显数据背后的真实含义，它为了把无序的数据转换成有用的信息。它致力于研究如何通过计算的手段，利用经验来改善系统自身的性能。
机器学习是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。

## 二、研究内容

机器学习所研究的主要内容，是关于在计算机上从数据中产生“模型（model）”的算法，即“学习算法（learning algorithm）”。有了学习算法，把经验数据提供给他，他就能基于这些数据产生模型。

## 三、研究意义及现状

机器学习是一门人工智能的科学，该领域的主要研究对象是人工智能，特别是如何在经验学习中改善具体算法的性能”。 “机器学习是对能通过经验自动改进的计算机算法的研究”。 “机器学习是用数据或以往的经验，以此优化计算机程序的性能标准。” 一种经常引用的英文定义是：A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.

机器学习已经有了十分广泛的应用，例如：数据挖掘、计算机视觉、自然语言处理、生物特征识别、搜索引擎、医学诊断、检测信用卡欺诈、证券市场分析、DNA序列测序、语音和手写识别、战略游戏和机器人运用。


> 机器学习已应用于多个领域，远远超出大多数人的想象，横跨：计算机科学、工程技术和统计学等多个学科。

* 搜索引擎: 根据你的搜索点击，优化你下次的搜索结果,是机器学习来帮助搜索引擎判断哪个结果更适合你（也判断哪个广告更适合你）。
* 垃圾邮件: 会自动的过滤垃圾广告邮件到垃圾箱内。
* 超市优惠券: 你会发现，你在购买小孩子尿布的时候，售货员会赠送你一张优惠券可以兑换6罐啤酒。
* 邮局邮寄: 手写软件自动识别寄送贺卡的地址。
* 申请贷款: 通过你最近的金融活动信息进行综合评定，决定你是否合格。

## 四、机器学习组成

### 1.主要任务

* 分类（classification）：将实例数据划分到合适的类别中，即计算机程序需要指定某些输入属于k类中的哪一类。
   * 应用实例：判断网站是否被黑客入侵（二分类 ），手写数字的自动识别（多分类）
* 回归（regression）：主要用于预测数值型数据，即计算机程序需要对给定的输入预测出数值。
   * 应用实例：股票价格波动的预测，房屋价格的预测等。

### 2.监督学习（supervised learning）

* 训练含有多特征的数据集，数据集中的每一个样本都有一个**标签(label)**或**目标(target)**。
* 例如：Iris数据集注明了每个鸢尾花样本属于什么品种，监督学习算法通过研究Iris数据集，学习如何根据测量结果将样本划分为不同的品种。


### 3.非监督学习（unsupervised learing）

* 在机器学习，无监督学习的问题是，在未加标签的数据中，试图找到隐藏的结构，数据没有类别信息，也不会给定目标值。因为提供给学习者的实例是未标记的，因此没有错误或报酬信号来评估潜在的解决方案。
* 无监督学习是密切相关的统计数据密度估计的问题。然而无监督学习还包括寻求，总结和解释数据的主要特点等诸多技术。在无监督学习使用的许多方法是基于用于处理数据的数据挖掘方法。

### 4.强化学习

* 这个算法可以训练程序做出某一决定。程序在某一情况下尝试所有的可能行动，记录不同行动的结果并试着找出最好的一次尝试来做决定。 
* 强化学习思路：个体选择一个合适的动作A，环境的状态会改变，同时得到采取动作A的奖励R，然后个体继续选择下一个合适的动作，环境的状态又会改变，又有新的奖励值。

### 5.算法汇总

![机器学习算法汇总](E:\▲▲▲机器学习总结▲▲▲\机器学习系列之机器学习基础\机器学习算法汇总.png)

### 6.模型

 * 分类问题 —— 将一些未知类别的数据分到现在已知的类别中去。评判分类效果好坏的三个指标：正确率，召回率，F值。
 * 回归问题 —— 对数值型连续随机变量进行预测和建模的监督学习算法。回归往往会通过计算 误差（Error）来确定模型的精确性。
 * 聚类问题 —— 聚类是一种无监督学习任务，该算法基于数据的内部结构寻找观察样本的自然族群（即集群）。聚类问题的标准一般基于距离：簇内距离（Intra-cluster Distance） 和 簇间距离（Inter-cluster Distance） 。簇内距离是越小越好，也就是簇内的元素越相似越好；而簇间距离越大越好，也就是说簇间（不同簇）元素越不相同越好。一般的，衡量聚类问题会给出一个结合簇内距离和簇间距离的公式。

![算法模型导图](E:\▲▲▲机器学习总结▲▲▲\机器学习系列之机器学习基础\算法模型导图.jpg)

### 7.开发流程

1. 收集数据: 收集样本数据
2. 准备数据: 注意数据的格式
3. 分析数据: 为了确保数据集中没有垃圾数据；
    * 如果是算法可以处理的数据格式或可信任的数据源，则可以跳过该步骤；
    * 另外该步骤需要人工干预，会降低自动化系统的价值。
4. 训练算法: [机器学习算法核心]如果使用无监督学习算法，由于不存在目标变量值，则可以跳过该步骤
5. 测试算法: [机器学习算法核心]评估算法效果
6. 使用算法: 将机器学习算法转为应用程序

## 五、机器学习基础

### 1.数据集的划分

 * 训练集（Training set） —— 学习样本数据集，通过匹配一些参数来建立一个模型，主要用来训练模型。类比考研前做的解题大全。
 * 验证集（validation set） —— 对学习出来的模型，调整模型的参数，如在神经网络中选择隐藏单元数。验证集还用来确定网络结构或者控制模型复杂程度的参数。类比考研之前做的模拟考试。
 * 测试集（Test set） —— 测试训练好的模型的分辨能力。类比考研。这次真的是一考定终身。

### 2.数据集划分方法

* **留出法（hold out）：**直接将数据集划分为两个互斥的集合，其中一个集合作为训练集，另一个集合作为测试集。在训练集上训练出模型后，用测试集来评估其测试误差，作为对泛化误差的估计，训练/测试集的划分要尽可能保持数据分布的一致性。在使用流出法时谜一般要采用若干次随机划分、重复进行试验评估后取平均值作为留出法的评估结果。

* **交叉验证（cross validation）：**先将数据集划分为k个大小相似的互斥子集（每个子集要尽可能保持数据分布的一致性）；然后，每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集（这样就可以获得k组训练/测试集，从而可进行k次训练和测试）；最终返回的是这k个测试结果的均值（k通常取10）。即：k折交叉验证通常要随机使用不同的划分重复p次，最终的评估结果是这p次k折交叉验证结果的均值。

  “10次10折交叉验证法”与“100次留出法”都是进行了100次训练/测试。

* **留一法（LOO）：**是交叉验证法的一个特例，即：每次只取一个样本作为测试集，其余样本作为训练集（留一法不受随机样本划分方式的影响，因为m个样本只有唯一的方式划分为m个子集）。留一法适用于数据集非常小的情况。

* **自助法（bootstrapping）：**给定包含m个样本的数据集D，我们对它进行采样产生数据集D’，每次随机从D中挑选一个样本，将其拷贝放入D‘，然后再将该样本放回初始数据集D中，使得该样本在下次采样时仍有可能被采到，这个过程重复执行m次后，我们就得到了包含m个样本的数据集D’（显然D中有一部分样本会在D‘中多次出现，而另一部分样本不出现，经概率统计计算可知：约36.8%的样本不会出现在D’中）。可将D‘作为训练集，将未出现在D’内的样本作为测试集。自助法在数据集较小、难以有效划分训练集/测试集时很有用。

### 3.模型拟合程度

 * 欠拟合（Underfitting）：模型没有很好地捕捉到数据特征，不能够很好地拟合数据，对训练样本的一般性质尚未学好。类比，光看书不做题觉得自己什么都会了，上了考场才知道自己啥都不会。
 * 过拟合（Overfitting）：模型把训练样本学习“太好了”，可能把一些训练样本自身的特性当做了所有潜在样本都有的一般性质，导致泛化能力下降。类比，课后题答案全背过了，上了考场发现题换了。 

    通俗来说，欠拟合和过拟合都可以用一句话来说，欠拟合就是：“你太天真了！”，过拟合就是：“你想太多了！”。

### 4.特征提取

 * 特征选择 —— 也叫特征子集选择（FSS，Feature Subset Selection）。是指从已有的 M 个特征（Feature）中选择 N 个特征使得系统的特定指标最优化，是从原始特征中选择出一些最有效特征以降低数据集维度的过程，是提高算法性能的一个重要手段，也是模式识别中关键的数据预处理步骤。

 * 特征提取 —— 特征提取是计算机视觉和图像处理中的一个概念。它指的是使用计算机提取图像信息，决定每个图像的点是否属于一个图像特征。特征提取的结果是把图像上的点分为不同的子集，这些子集往往属于孤立的点，连续的曲线或者连续的区域。

![特征工程](E:\▲▲▲机器学习总结▲▲▲\机器学习系列之机器学习基础\特征工程.png)

## 六、性能度量
性能度量反映了任务需求。什么样的模型是好的，不仅取决于算法和数据，还取决于任务需求。

### 1.错误率与精度
这是分类任务中最常用的两种性能度量，既适用于二分类任务，也适用于多分类任务。

$$
错误率 = \frac{分类错误的样本数}{样本总数}
$$

$$
精度 = 1 - 错误率
$$

### 2.查全率、查准率与F1

$$
分类结果混淆矩阵
$$
<table border="1">
    <tr>
        <th rowspan="2">真实情况</td>
        <th colspan="2">预测结果</td>
	</tr>
    <tr>
         <td>正例</td>
         <td>负例</td>
	</tr> 
     <tr>
          <td>正例</td>
          <td>TP（真正例）</td>
          <td>FN（假反例）</td>
	</tr>
	<tr>
        <td>反例</td>
        <td>FP（假反例）</td>
        <td>TN（真反例）</td>
	</tr>

其中：TP+FP+TN+FN=样例总数

$$
查准率P = \frac{TP}{TP+FP}
$$

$$
查全率R = \frac{TP}{TP+FN}
$$

查准率高时，查全率往往偏低；查全率高时，查准率往往偏低。

F1是用来寻找最佳P和R的值，F1介于（0，1）之间且F1越大越好。
$$
F1 = \frac{2 \times p \times R}{P + R}
$$

### 3.ROC与AUC

* **ROC（受试者工作特征）：**其主要分析工具是一个画在二维平面上的曲线。平面的横坐标是假正例率(FPR)，纵坐标是真正例率(TPR)。对某个分类器而言，我们可以根据其在测试样本上的表现得到一个TPR和FPR点对。这样，此分类器就可以映射成ROC平面上的一个点。

$$
TPR = \frac{TP}{TP + FN}
$$

$$
FPR = \frac{FP}{TN+FP}
$$

* **ROC曲线绘制流程：**给定m+个正例和m-个反例，根据学习器对预测结果对样例进行排序，然后把分类阈值设为最大，即把所有样例均预测为反例，此时真正率和假正率均为0，坐标（0，0）处标记一个点。然后，依次将每个样例划分为正例。设前一个标记点坐标为（x，y），当前若为真正例，则对应标记点的坐标为（x,y+(1/m+)）;当前若为假正例，则对应标记点的坐标为（x+(1/m-),y），然后用线段连接相邻点即可。

* **AUC：**的值就是ROC曲线下方的面积。虽然，用ROC曲线来表示分类器的性能很直观好用。但是人们希望能有一个数值来表示分类器的好坏。于是AUC就出现了。通常，AUC的值介于0.5到1.0之间，较大的AUC代表了较好的性能。

$$
AUC = \frac{1}{2} \sum_{i=1}^{m-1}(x_{i+1} - x_i)·（y_i + y_{i+1}）
$$


### 4.偏差与方差

**“偏差—方差分解”**是解释学习算法泛化性能的一种重要工具，泛化误差可分解为偏差、方差与噪声之和。

* **偏差**度量了学习算法的期望预测与真实结果的偏离程度，即：刻画了学习算法本身的拟合能力；
* **方差**度量了同样大小的训练集的变动所导致的学习性能的变化，即：刻画了数据扰动所造成的影响；
* **噪声**表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即：刻画了学习问题本身的难度。

**偏差—方差**分解说明，泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的。为了取得好的泛化性能，则需使偏差较小，即能够充分拟合数据，并且使方差较小，即使的数据扰动产生的影响小。偏差与方差是有冲突的，这称为**偏差—方差窘境**。

* 在训练不足时，学习器的拟合能力不够强，训练数据的扰动不足以使学习器产生显著变化，此时偏差主导了泛化错误率；
* 随着训练程度的加深，学习器的拟合能力逐渐增强，训练数据发生的扰动渐渐能被学习器学到，方差逐渐主导了泛化错误率。

![泛化误差与偏差-方差](E:\▲▲▲机器学习总结▲▲▲\机器学习系列之机器学习基础\泛化误差与偏差-方差.png)

## 附：机器学习专业术语

* 模型（model）：计算机层面的认知
* 学习算法（learning algorithm），从数据中产生模型的方法
* 数据集（data set）：一组记录的合集
* 示例（instance）：对于某个对象的描述
* 样本（sample）：也叫示例
* 属性（attribute）：对象的某方面表现或特征
* 特征（feature）：同属性
* 属性值（attribute value）：属性上的取值
* 属性空间（attribute space）：属性张成的空间
* 样本空间/输入空间（samplespace）：同属性空间
* 特征向量（feature vector）：在属性空间里每个点对应一个坐标向量，把一个示例称作特征向量
* 维数（dimensionality）：描述样本参数的个数（也就是空间是几维的）
* 学习（learning）/训练（training）：从数据中学得模型
* 训练数据（training data）：训练过程中用到的数据
* 训练样本（training sample）:训练用到的每个样本
* 训练集（training set）：训练样本组成的集合
* 训练误差（training error）：学习器在训练集上的误差
* 泛化误差（generalization error）：在新样本上的误差
* 假设（hypothesis）：学习模型对应了关于数据的某种潜在规则
* 真相（ground-truth）:真正存在的潜在规律
* 学习器（learner）：模型的另一种叫法，把学习算法在给定数据和参数空间的实例化
* 调参（parameter tuning）：对算法参数进行设定
* 预测（prediction）：判断一个东西的属性
* 标记（label）：关于示例的结果信息，比如我是一个“好人”。
* 样例（example）：拥有标记的示例
* 标记空间/输出空间（label space）：所有标记的集合
* 分类（classification）：预测是离散值，比如把人分为好人和坏人之类的学习任务
* 回归（regression）：预测值是连续值，比如你的好人程度达到了0.9，0.6之类的
* 二分类（binary classification）：只涉及两个类别的分类任务
* 正类（positive class）：二分类里的一个
* 反类（negative class）：二分类里的另外一个
* 多分类（multi-class classification）：涉及多个类别的分类
* 测试（testing）：学习到模型之后对样本进行预测的过程
* 测试样本（testing sample）：被预测的样本
* 聚类（clustering）：把训练集中的对象分为若干组
* 簇（cluster）：每一个组叫簇
* 监督学习（supervised learning）：典范--分类和回归
* 无监督学习（unsupervised learning）：典范--聚类
* 未见示例（unseen instance）：“新样本“，没训练过的样本
* 泛化（generalization）能力：学得的模型适用于新样本的能力
* 分布（distribution）：样本空间的全体样本服从的一种规律
* 独立同分布（independent and identically distributed，简称i,i,d.）:获得的每个样本都是独立地从这个分布上采样获得的。

【参考文章】
* apache github主页：https://github.com/apachecn/AiLearning
* 周志华 《机器学习》
* 伊恩 古德费洛、约书亚 本吉奥 和 亚伦 库维尔 《深度学习》
